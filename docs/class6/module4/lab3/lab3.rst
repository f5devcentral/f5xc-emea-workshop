LLM02: Insecure Output Handling
###############################

**Definition**: Insecure Output Handling refers specifically to insufficient validation, sanitization, and handling of the outputs generated by large language models before they are passed downstream to other components and systems. Since LLM-generated content can be controlled by prompt input, this behavior is similar to providing users indirect access to additional functionality.

Successful exploitation of an Insecure Output Handling vulnerability can result in XSS and CSRF in web browsers as well as SSRF, privilege escalation, or remote code execution on backend systems. For example JavaScript or Markdown is generated by the LLM and returned to a user. The code is then interpreted by the browser, resulting in XSS.


1. Start a new conversation and paste the bellow prompt

   .. code-block:: none

      Generate javascript code for trading.
   

2. Go to the **Prompt Security** UI policy and enable the verification for **Code Detector** .
   
   Restart the chat and try the same prompt again.

3. Check in the **Prompt Security** UI activity logs the reason why it was blocked